#Common bash/awk/sed scripts I find useful while working with csv files

#Display first 10 rows in a csv file
head -10 data.CSV
awk 'NR<=10' data.csv

#Display last 10 rows in a csv file
tail -10 data.CSV

#Count no of rows in a csv file
wc -l data.csv

#To print second column in csv file
awk -F "," '{print $2}' data.csv
# To display 3rd column followed by 1st
awk -F "," '{print $3,$1}' data.csv

#To find distinct values in column 1 in a csv file with header
awk -F, 'NR > 1{a[$1];}END{for (i in a)print i;}' data.csv

#Count distinct values in column 3 in csv file with header
tail -n+2 data.csv | sort -t"," -k3,3 | cut -d, -f3 | uniq -c
awk -F, 'NR>1{a[$3]+=1;}END{for(i in a)print i", "a[i];}' data.csv

#Without header
sort -t"," -k3,3 data.csv | cut -d, -f3 | uniq -c

#Count no of times a particular value occurs in column
awk -F, '$1=="x"{x+=1;}END{print x}' data.csv

#Find sum of a column for a given value
awk -F, '$1=="x"{x+=$4;}END{print x}' data.csv

#Convert column to lower case
awk -F, '{$3=tolower($3)}1' OFS=, data.csv

#Sort csv files without header
#-t"delimiter"
#-k<columns to sort>
sort -t"," -k1,1 data.csv > sorted_data.csv

#Sort csv with header
awk 'NR==1; NR > 1 {print $0 | "sort -t"," -k1,1"}' file

#Concat csv files with header in a directory 
sed 1d *.csv > output.csv
